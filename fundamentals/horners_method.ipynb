{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horner's Method\n",
    "\n",
    "What is the best way to evaluate \n",
    "\n",
    "\\\\[ f(x) = x^3 + 4x^2 - 10 \\\\]\n",
    "\n",
    "at $ x = \\dfrac{1}{2} $? The traditional and direct approach is\n",
    "\n",
    "\\\\[ f(\\dfrac{1}{2}) = \\dfrac{1}{2} * \\dfrac{1}{2} * \\dfrac{1}{2} + 4 * \\dfrac{1}{2} * \\dfrac{1}{2} - 10 \\\\]\n",
    "\n",
    "This procedure takes 4 multiplications and 2 additions where a subtraction can be interpreted as adding a negative number. All together it takes 6 operations to evaluate the function. Is there a way to reduce the number of operations? Rewrite the polynomial in such a way the variable $x$ is factored out:\n",
    " \n",
    "\\begin{align}\n",
    "f(x) & = -10 + 4x^2 + x^3 \\\\\n",
    " & = -10 + x * (0 + 4x + x^2 ) \\\\\n",
    " & = -10 + x * (0 + x * (4 + x))\n",
    "\\end{align}\n",
    "\n",
    "As you can see, it takes a total of 5 operations to evaluate the function; 3 additions and 2 multiplications. This method is called **Horner's Method**.\n",
    "The point of this notebook is to check the absolute error and relative error and to test the efficiency of using Horner's Method for numerical computations. In this case, we explore its application to find the root of the equation using Bisection Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute and Relative Error\n",
    "To calculate the error between the two functions we need to find the absolute and the relative error where $x^*$ is the approximate function and $x$ is the true function.\n",
    "\n",
    "**Absolute Error** $= |x^* - x| $\n",
    "\n",
    "**Relative Error** $= \\dfrac{|x^* - x|}{|x|} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(true_fx, approx_fx):\n",
    "    absolute_error = abs(approx_fx - true_fx)\n",
    "    relative_error = absolute_error / abs(true_fx)\n",
    "    return absolute_error, relative_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Function - Naive Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x ** 3) + (4 * (x ** 2)) - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximate Function - Horner's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_a(x):\n",
    "    return -10 + ùë• * (0 + ùë• * (4 + ùë•))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisection Method\n",
    "Bisection method is a root-finding algorithm based from the intermediate-value theorem from calculus.\n",
    "You need to verify if a root exist by making sure the two endpoints of the interval $ [a,b] $ or $\\{f(a),f(b)\\}$ have different signs. If function $ f $ is continuous, then there will be a root $r$ between $a$ and $b$ such that $f(r) = 0$ and $a < r < b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method(a,b):\n",
    "    if f(a) * f(b) < 0: \n",
    "        roots = []\n",
    "        while (b - a) / 2 > 1e-7:\n",
    "            c = (a + b) / 2          \n",
    "            if f(a) * f(c) < 0:\n",
    "                b = c\n",
    "            else:\n",
    "                a = c\n",
    "            roots.append(c)\n",
    "    return np.array(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7 ¬µs ¬± 1.49 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "roots = bisection_method(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = bisection_method(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method_hm(a,b):\n",
    "    if f_a(a) * f_a(b) < 0: \n",
    "        roots = []\n",
    "        while (b - a) / 2 > 1e-7:\n",
    "            c = (a + b) / 2          \n",
    "            if f_a(a) * f_a(c) < 0:\n",
    "                b = c\n",
    "            else:\n",
    "                a = c\n",
    "            roots.append(c)\n",
    "    return np.array(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ¬µs ¬± 4.59 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "roots_a = bisection_method_hm(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots_a = bisection_method(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the benchmark an implementation of the Horner's Method perform faster than the naive method. Now let us look at the error analysis to find out whether results are different on a precision level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error, relative_error = error_analysis(roots, roots_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily errors were not found in this example, however polynomials should always be expressed in the nested form before performing an evaluation, because this form minimizes the number of arithmetic calculations, as a result, the errors are reduced. The example \\begin{align}\n",
    "f(x) & = -10 + 4x^2 + x^3 \\\\\n",
    " & = -10 + x * (0 + 4x + x^2 ) \\\\\n",
    " & = -10 + x * (0 + x * (4 + x))\n",
    "\\end{align}\n",
    "\n",
    "has already placed the coefficients and the variables in the rightful place. Notice we placed an additional coefficient $0$ to fill-in the missing degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using Horner's Method\n",
    "\n",
    "As an engineer we can write an algorithm to evaluate `x` given only the `degree` (or the number of terms in a polynomial) and its `coefficients`. This way we don't have to rewrite a function everytime a new polynomial is introduced.\n",
    "\n",
    "Consider the following polynomial $ P(x) = a_{k}x^{k} + a_{k-1}x^{k-1} + a_{k-2}x^{k-2} + ... + a_{1}x + a_{0} $ we can evaluate `x` using this algorithm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, k, c, b=None):\n",
    "    '''\n",
    "    Evaluate `x` from a polynomial using Horner's Method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int or float\n",
    "            The value of x\n",
    "    k : int\n",
    "            degrees or the number of terms\n",
    "    c : int or float\n",
    "            coefficients\n",
    "    b : int or float\n",
    "            base points\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : int or float\n",
    "            The output of the polynomial\n",
    "    '''\n",
    "    y = c[0]\n",
    "    if b is None:\n",
    "        for i in range(1, k):\n",
    "            y = c[i] + (x * y)\n",
    "    else:\n",
    "        for i in range(1, k):\n",
    "            y = (y * (x - b[i])) + c[i]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684 ns ¬± 9.99 ns per loop (mean ¬± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "evaluate(2, 4, [1, 4, 0, -10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ns ¬± 2.02 ns per loop (mean ¬± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f_a(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 ns ¬± 9.06 ns per loop (mean ¬± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Horner's method is slower in comparison with functions whose polynomials are laid out, this method still is efficient as it saves time to rewrite equations and evaluate. We shall look more into the applications of Horner's Method once we get into Interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "- R.L. Burden and J.D. Faires. *Numerical Analysis*. Brooks/Cole, Cengage Learning, Boston, 9th edition, 2010.\n",
    "- Timothy Sauer. 2018. *Numerical Analysis (3rd. ed.)*. Pearson, UK.\n",
    "- Justin Solomon. 2015. *Numerical Algorithms: Methods for Computer Vision, Machine Learning, and Graphics*. A. K. Peters, Ltd., USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bita1db1c83d908435e9cdbf86dec23a524"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
