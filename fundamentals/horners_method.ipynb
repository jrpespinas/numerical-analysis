{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horner's Method\n",
    "\n",
    "What is the best way to evaluate \n",
    "\n",
    "\\\\[ f(x) = x^3 + 4x^2 - 10 \\\\]\n",
    "\n",
    "at $ x = \\dfrac{1}{2} $? The traditional and direct approach is\n",
    "\n",
    "\\\\[ f(2) = \\dfrac{1}{2} * \\dfrac{1}{2} * \\dfrac{1}{2} + 4 * \\dfrac{1}{2} * \\dfrac{1}{2} - 10 \\\\]\n",
    "\n",
    "This procedure takes 4 multiplications and 2 additions where a subtraction can be interpreted as adding a negative number. All together it takes 6 operations to evaluate the function. Is there a way to reduce the number of operations? Rewrite the polynomial in such a way the variable $x$ is factored out:\n",
    " \n",
    "\\begin{align}\n",
    "f(x) & = -10 + 4x^2 + x^3 \\\\\n",
    " & = -10 + x * (0 + 4x + x^2 ) \\\\\n",
    " & = -10 + x * (0 + x * (4 + x))\n",
    "\\end{align}\n",
    "\n",
    "As you can see, it takes a total of 5 operations to evaluate the function; 3 additions and 2 multiplications. This method is called **Horner's Method**.\n",
    "The point of this notebook is to check the absolute error and relative error and to test the efficiency of using Horner's Method for numerical computations. In this case, we explore its application to find the root of the equation using Bisection Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute and Relative Error\n",
    "To calculate the error between the two functions we need to find the absolute and the relative error where $x^*$ is the approximate function and $x$ is the true function.\n",
    "\n",
    "**Absolute Error** $= |x^* - x| $\n",
    "\n",
    "**Relative Error** $= \\dfrac{|x^* - x|}{|x|} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(true_fx, approx_fx):\n",
    "    absolute_error = abs(approx_fx - true_fx)\n",
    "    relative_error = absolute_error / abs(true_fx)\n",
    "    return absolute_error, relative_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Function - Naive Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x ** 3) + (4 * (x ** 2)) - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Function - Horner's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_a(x):\n",
    "    return -10 + ùë• * (0 + ùë• * (4 + ùë•))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bisection Method\n",
    "Bisection method is a root-finding algorithm based from the intermediate-value theorem from calculus.\n",
    "You need to verify if a root exist by making sure the two endpoints of the interval $ [a,b] $ or $\\{f(a),f(b)\\}$ have different signs. If function $ f $ is continuous, then there will be a root $r$ between $a$ and $b$ such that $f(r) = 0$ and $a < r < b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method(a,b):\n",
    "    if f(a) * f(b) < 0: \n",
    "        roots = []\n",
    "        while (b - a) / 2 > 1e-7:\n",
    "            c = (a + b) / 2          \n",
    "            if f(a) * f(c) < 0:\n",
    "                b = c\n",
    "            else:\n",
    "                a = c\n",
    "            roots.append(c)\n",
    "    return np.array(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 ¬µs ¬± 1.55 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "roots = bisection_method(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_method_hm(a,b):\n",
    "    if f_a(a) * f_a(b) < 0: \n",
    "        roots = []\n",
    "        while (b - a) / 2 > 1e-7:\n",
    "            c = (a + b) / 2          \n",
    "            if f_a(a) * f_a(c) < 0:\n",
    "                b = c\n",
    "            else:\n",
    "                a = c\n",
    "            roots.append(c)\n",
    "    return np.array(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.2 ¬µs ¬± 1.06 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "roots_a = bisection_method_hm(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the benchmark an implementation of the Horner's Method perform faster than the naive method. Now let us look at the error analysis to determine whether results are different on a precision level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bita1db1c83d908435e9cdbf86dec23a524"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
